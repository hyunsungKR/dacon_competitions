{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸ”® ê±´ì„¤ìš© ìžê°ˆ ì•”ì„ ë¶„ë¥˜ AI - ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "\n",
        "## ðŸ“‹ ëª©í‘œ\n",
        "- í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
        "- ëŒ€íšŒ ì œì¶œ íŒŒì¼ ìƒì„± (sample_submission.csv í˜•ì‹)\n",
        "- ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ë° í’ˆì§ˆ ê²€ì¦\n",
        "\n",
        "## ðŸŽ¯ ì§„í–‰ ê³¼ì •\n",
        "1. í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\n",
        "2. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n",
        "3. ë°°ì¹˜ ë‹¨ìœ„ ì¶”ë¡  ì‹¤í–‰\n",
        "4. ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "5. ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wang\\anaconda3\\envs\\yolo\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: Malgun Gothic\n",
            "ðŸ”® ê±´ì„¤ìš© ìžê°ˆ ì•”ì„ ë¶„ë¥˜ AI - ì¶”ë¡  ì‹œìž‘!\n",
            "PyTorch ë²„ì „: 2.2.2+cu121\n",
            "CUDA ì‚¬ìš© ê°€ëŠ¥: True\n",
            "GPU: NVIDIA GeForce RTX 4070\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸ“¦ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# ë°ì´í„° ì²˜ë¦¬\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# ë”¥ëŸ¬ë‹\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "\n",
        "# ì‹œê°í™”\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# ê²½ê³  ì–µì œ\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "def setup_korean_font():\n",
        "    \"\"\"Windows í™˜ê²½ì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •\"\"\"\n",
        "    font_names = ['Malgun Gothic', 'NanumGothic', 'DejaVu Sans']\n",
        "    \n",
        "    for font_name in font_names:\n",
        "        try:\n",
        "            font_path = None\n",
        "            for font in font_manager.fontManager.ttflist:\n",
        "                if font_name.lower() in font.name.lower():\n",
        "                    font_path = font.fname\n",
        "                    break\n",
        "            \n",
        "            if font_path:\n",
        "                plt.rcParams['font.family'] = font_name\n",
        "                plt.rcParams['axes.unicode_minus'] = False\n",
        "                print(f\"âœ… í•œê¸€ í°íŠ¸ ì„¤ì • ì™„ë£Œ: {font_name}\")\n",
        "                return True\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    print(\"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì • ì‹¤íŒ¨ - ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©\")\n",
        "    return False\n",
        "\n",
        "setup_korean_font()\n",
        "\n",
        "# ì‹œë“œ ê³ ì •\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print(\"ðŸ”® ê±´ì„¤ìš© ìžê°ˆ ì•”ì„ ë¶„ë¥˜ AI - ì¶”ë¡  ì‹œìž‘!\")\n",
        "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
        "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:\n",
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°: D:\\data\\stones\\open\\test\n",
            "í…ŒìŠ¤íŠ¸ CSV: D:\\data\\stones\\open\\test.csv\n",
            "ëª¨ë¸ ì €ìž¥: ..\\models\n",
            "ê²°ê³¼ ì €ìž¥: ..\\results\n",
            "\n",
            "ðŸ·ï¸ í´ëž˜ìŠ¤ ì •ë³´:\n",
            "í´ëž˜ìŠ¤ ìˆ˜: 7\n",
            "í´ëž˜ìŠ¤ ëª©ë¡: ['Andesite', 'Basalt', 'Etc', 'Gneiss', 'Granite', 'Mud_Sandstone', 'Weathered_Rock']\n",
            "\n",
            "ðŸ’» ì—°ì‚° ìž¥ì¹˜: cuda\n",
            "GPU ë©”ëª¨ë¦¬: 12.0 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸ”§ ê²½ë¡œ ë° ì„¤ì • ë¡œë“œ\n",
        "# ============================================================================\n",
        "\n",
        "# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •\n",
        "BASE_PATH = r\"D:\\data\\stones\\open\"\n",
        "TEST_PATH = os.path.join(BASE_PATH, \"test\")\n",
        "TEST_CSV_PATH = os.path.join(BASE_PATH, \"test.csv\")\n",
        "SUBMISSION_PATH = os.path.join(BASE_PATH, \"sample_submission.csv\")\n",
        "\n",
        "# í”„ë¡œì íŠ¸ ê²½ë¡œ\n",
        "MODEL_DIR = Path(\"../models\")\n",
        "EXPERIMENT_DIR = Path(\"../experiments\")\n",
        "RESULTS_DIR = Path(\"../results\")\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ì‹¤í—˜ ì„¤ì • ë¡œë“œ\n",
        "config_path = EXPERIMENT_DIR / \"experiment_config.json\"\n",
        "with open(config_path, 'r', encoding='utf-8') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# í´ëž˜ìŠ¤ ì •ë³´\n",
        "CLASS_NAMES = config['project_info']['class_names']\n",
        "NUM_CLASSES = config['project_info']['num_classes']\n",
        "class_to_idx = {cls: i for i, cls in enumerate(CLASS_NAMES)}\n",
        "idx_to_class = {i: cls for cls, i in class_to_idx.items()}\n",
        "\n",
        "# ë””ë°”ì´ìŠ¤ ì„¤ì •\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"ðŸ“‚ ê²½ë¡œ ì„¤ì • ì™„ë£Œ:\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {TEST_PATH}\")\n",
        "print(f\"í…ŒìŠ¤íŠ¸ CSV: {TEST_CSV_PATH}\")\n",
        "print(f\"ëª¨ë¸ ì €ìž¥: {MODEL_DIR}\")\n",
        "print(f\"ê²°ê³¼ ì €ìž¥: {RESULTS_DIR}\")\n",
        "\n",
        "print(f\"\\nðŸ·ï¸ í´ëž˜ìŠ¤ ì •ë³´:\")\n",
        "print(f\"í´ëž˜ìŠ¤ ìˆ˜: {NUM_CLASSES}\")\n",
        "print(f\"í´ëž˜ìŠ¤ ëª©ë¡: {CLASS_NAMES}\")\n",
        "\n",
        "print(f\"\\nðŸ’» ì—°ì‚° ìž¥ì¹˜: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f} GB\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\n",
            "1. EfficientNetV2-S_quick_baseline\n",
            "   í¬ê¸°: 232.3 MB\n",
            "   ìˆ˜ì •: 2025-08-23 04:55:16\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸ­ ëª¨ë¸ íŒ©í† ë¦¬ ë° ë¡œë”\n",
        "# ============================================================================\n",
        "\n",
        "class ModelFactory:\n",
        "    \"\"\"ë‹¤ì–‘í•œ ëª¨ë¸ ì•„í‚¤í…ì²˜ë¥¼ ìƒì„±í•˜ëŠ” íŒ©í† ë¦¬ í´ëž˜ìŠ¤\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=7, pretrained=False):\n",
        "        \"\"\"ëª¨ë¸ ìƒì„±\"\"\"\n",
        "        try:\n",
        "            # timmì„ í†µí•œ ëª¨ë¸ ìƒì„±\n",
        "            model = timm.create_model(\n",
        "                model_name,\n",
        "                pretrained=pretrained,\n",
        "                num_classes=num_classes\n",
        "            )\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ìƒì„± ì‹¤íŒ¨ ({model_name}): {e}\")\n",
        "            return None\n",
        "\n",
        "class ModelLoader:\n",
        "    \"\"\"í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” í´ëž˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.model_info = None\n",
        "    \n",
        "    def load_model(self, model_path, model_name):\n",
        "        \"\"\"ì €ìž¥ëœ ëª¨ë¸ ë¡œë“œ\"\"\"\n",
        "        try:\n",
        "            print(f\"ðŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_path}\")\n",
        "            \n",
        "            # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
        "            checkpoint = torch.load(model_path, map_location=self.device)\n",
        "            \n",
        "            # ëª¨ë¸ ìƒì„±\n",
        "            self.model = ModelFactory.create_model(model_name, NUM_CLASSES)\n",
        "            if self.model is None:\n",
        "                return False\n",
        "            \n",
        "            # ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            \n",
        "            # ëª¨ë¸ ì •ë³´ ì €ìž¥\n",
        "            self.model_info = {\n",
        "                'model_path': str(model_path),\n",
        "                'model_name': model_name,\n",
        "                'best_score': checkpoint.get('best_score', 'N/A'),\n",
        "                'epoch': checkpoint.get('epoch', 'N/A'),\n",
        "                'total_params': sum(p.numel() for p in self.model.parameters())\n",
        "            }\n",
        "            \n",
        "            print(f\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
        "            print(f\"   ëª¨ë¸ ì•„í‚¤í…ì²˜: {model_name}\")\n",
        "            print(f\"   ìµœê³  ì„±ëŠ¥: {self.model_info['best_score']}\")\n",
        "            print(f\"   ì´ íŒŒë¼ë¯¸í„°: {self.model_info['total_params']:,}ê°œ\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_available_models(self):\n",
        "        \"\"\"ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜\"\"\"\n",
        "        model_files = list(MODEL_DIR.glob(\"*.pth\"))\n",
        "        \n",
        "        available = []\n",
        "        for model_file in model_files:\n",
        "            # íŒŒì¼ëª…ì—ì„œ ëª¨ë¸ ì •ë³´ ì¶”ì¶œ\n",
        "            model_info = {\n",
        "                'path': model_file,\n",
        "                'name': model_file.stem,\n",
        "                'size_mb': model_file.stat().st_size / (1024 * 1024),\n",
        "                'modified': datetime.fromtimestamp(model_file.stat().st_mtime)\n",
        "            }\n",
        "            available.append(model_info)\n",
        "        \n",
        "        # ìˆ˜ì • ì‹œê°„ìˆœ ì •ë ¬ (ìµœì‹  ìˆœ)\n",
        "        available.sort(key=lambda x: x['modified'], reverse=True)\n",
        "        \n",
        "        return available\n",
        "\n",
        "# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸\n",
        "model_loader = ModelLoader(device)\n",
        "available_models = model_loader.get_available_models()\n",
        "\n",
        "print(\"ðŸ” ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\")\n",
        "if available_models:\n",
        "    for i, model_info in enumerate(available_models, 1):\n",
        "        print(f\"{i}. {model_info['name']}\")\n",
        "        print(f\"   í¬ê¸°: {model_info['size_mb']:.1f} MB\")\n",
        "        print(f\"   ìˆ˜ì •: {model_info['modified'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "else:\n",
        "    print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "    print(\"   ë¨¼ì € 03_model_training.ipynbì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ“‚ ì„ íƒëœ ëª¨ë¸: EfficientNetV2-S_quick_baseline\n",
            "   ê²½ë¡œ: ..\\models\\EfficientNetV2-S_quick_baseline.pth\n",
            "   í¬ê¸°: 232.3 MB\n",
            "   ì•„í‚¤í…ì²˜: tf_efficientnetv2_s.in21k_ft_in1k\n",
            "ðŸ“‚ ëª¨ë¸ ë¡œë“œ ì¤‘: ..\\models\\EfficientNetV2-S_quick_baseline.pth\n",
            "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
            "   ëª¨ë¸ ì•„í‚¤í…ì²˜: tf_efficientnetv2_s.in21k_ft_in1k\n",
            "   ìµœê³  ì„±ëŠ¥: 0.7997457306490847\n",
            "   ì´ íŒŒë¼ë¯¸í„°: 20,186,455ê°œ\n",
            "\n",
            "ðŸŽ¯ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\n",
            "   ì¶”ë¡  ì¤€ë¹„ ìƒíƒœ: âœ…\n",
            "   GPU ì‚¬ìš©: True\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸ”® í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ\n",
        "# ============================================================================\n",
        "\n",
        "if not available_models:\n",
        "    print(\"âŒ ë¡œë“œí•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "    print(\"   ë¨¼ì € 03_model_training.ipynbì—ì„œ ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.\")\n",
        "else:\n",
        "    # ê°€ìž¥ ìµœì‹  ëª¨ë¸ ì„ íƒ\n",
        "    latest_model = available_models[0]\n",
        "    model_path = latest_model['path']\n",
        "    \n",
        "    print(f\"ðŸ“‚ ì„ íƒëœ ëª¨ë¸: {latest_model['name']}\")\n",
        "    print(f\"   ê²½ë¡œ: {model_path}\")\n",
        "    print(f\"   í¬ê¸°: {latest_model['size_mb']:.1f} MB\")\n",
        "    \n",
        "    # ëª¨ë¸ëª… ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)\n",
        "    if \"EfficientNetV2-S\" in latest_model['name']:\n",
        "        model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
        "    elif \"EfficientNetV2-M\" in latest_model['name']:\n",
        "        model_name = \"tf_efficientnetv2_m.in21k_ft_in1k\"\n",
        "    elif \"ConvNeXt\" in latest_model['name']:\n",
        "        model_name = \"convnext_tiny.fb_in22k_ft_in1k\"\n",
        "    elif \"ViT\" in latest_model['name']:\n",
        "        model_name = \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\"\n",
        "    else:\n",
        "        model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"  # ê¸°ë³¸ê°’\n",
        "    \n",
        "    print(f\"   ì•„í‚¤í…ì²˜: {model_name}\")\n",
        "    \n",
        "    # ëª¨ë¸ ë¡œë“œ\n",
        "    success = model_loader.load_model(model_path, model_name)\n",
        "    \n",
        "    if success:\n",
        "        print(f\"\\nðŸŽ¯ ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ!\")\n",
        "        print(f\"   ì¶”ë¡  ì¤€ë¹„ ìƒíƒœ: âœ…\")\n",
        "        print(f\"   GPU ì‚¬ìš©: {next(model_loader.model.parameters()).is_cuda}\")\n",
        "    else:\n",
        "        print(f\"\\nâŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!\")\n",
        "        model_loader.model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸŽ¨ í…ŒìŠ¤íŠ¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸:\n",
            "   1. Resize: 224Ã—224 (BICUBIC)\n",
            "   2. ToTensor: [0,255] â†’ [0,1]\n",
            "   3. Normalize: ImageNet í‘œì¤€\n",
            "   âš ï¸ ì¦ê°• ì—†ìŒ (ì¼ê´€ëœ ì˜ˆì¸¡ì„ ìœ„í•´)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë° ì¶”ë¡  íŒŒì´í”„ë¼ì¸\n",
        "# ============================================================================\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ í´ëž˜ìŠ¤\"\"\"\n",
        "    \n",
        "    def __init__(self, test_csv_path, test_dir, transform=None):\n",
        "        self.test_df = pd.read_csv(test_csv_path)\n",
        "        self.test_dir = test_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "        print(f\"ðŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:\")\n",
        "        print(f\"   ì´ ìƒ˜í”Œ ìˆ˜: {len(self.test_df):,}ê°œ\")\n",
        "        print(f\"   CSV ì»¬ëŸ¼: {list(self.test_df.columns)}\")\n",
        "        \n",
        "        # ìƒ˜í”Œ ê²½ë¡œ í™•ì¸\n",
        "        sample_img_path = self.test_df.iloc[0]['img_path']\n",
        "        if sample_img_path.startswith('./'):\n",
        "            # ./ë¥¼ ì œê±°í•˜ê³  BASE_PATHì™€ ì¡°ì¸\n",
        "            relative_path = sample_img_path[2:]\n",
        "            base_path = os.path.dirname(self.test_dir)\n",
        "            sample_path = os.path.join(base_path, relative_path)\n",
        "        else:\n",
        "            sample_path = os.path.join(self.test_dir, sample_img_path)\n",
        "            \n",
        "        if os.path.exists(sample_path):\n",
        "            print(f\"âœ… ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸ ì™„ë£Œ\")\n",
        "        else:\n",
        "            print(f\"âŒ ì´ë¯¸ì§€ ê²½ë¡œ ì˜¤ë¥˜: {sample_path}\")\n",
        "            print(f\"   ì›ë³¸ img_path: {sample_img_path}\")\n",
        "            print(f\"   test_dir: {self.test_dir}\")\n",
        "            print(f\"   base_path: {os.path.dirname(self.test_dir)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.test_df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # ì´ë¯¸ì§€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
        "        img_id = self.test_df.iloc[idx]['ID']\n",
        "        img_path = self.test_df.iloc[idx]['img_path']\n",
        "        \n",
        "        # ì´ë¯¸ì§€ ë¡œë“œ (img_pathê°€ ì´ë¯¸ ./test/ë¥¼ í¬í•¨í•˜ë¯€ë¡œ BASE_PATH ì‚¬ìš©)\n",
        "        # img_path í˜•íƒœ: \"./test/TEST_00000.jpg\"\n",
        "        if img_path.startswith('./'):\n",
        "            # ./ë¥¼ ì œê±°í•˜ê³  BASE_PATHì™€ ì¡°ì¸\n",
        "            relative_path = img_path[2:]  # \"./test/TEST_00000.jpg\" -> \"test/TEST_00000.jpg\"\n",
        "            base_path = os.path.dirname(self.test_dir)  # D:\\data\\stones\\open\\test -> D:\\data\\stones\\open\n",
        "            full_path = os.path.join(base_path, relative_path)\n",
        "        else:\n",
        "            # ê¸°ì¡´ ë°©ì‹ (í˜¹ì‹œ ê²½ë¡œ í˜•íƒœê°€ ë‹¤ë¥¼ ê²½ìš°ë¥¼ ìœ„í•œ fallback)\n",
        "            full_path = os.path.join(self.test_dir, img_path)\n",
        "        \n",
        "        try:\n",
        "            image = Image.open(full_path).convert('RGB')\n",
        "            \n",
        "            # ë³€í™˜ ì ìš©\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return {\n",
        "                'image': image,\n",
        "                'id': img_id,\n",
        "                'path': img_path\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨ ({img_path}): {e}\")\n",
        "            print(f\"   ì‹œë„í•œ ê²½ë¡œ: {full_path}\")\n",
        "            # ë¹ˆ ì´ë¯¸ì§€ ë°˜í™˜\n",
        "            dummy_image = torch.zeros(3, 224, 224)\n",
        "            return {\n",
        "                'image': dummy_image,\n",
        "                'id': img_id,\n",
        "                'path': img_path\n",
        "            }\n",
        "\n",
        "# í…ŒìŠ¤íŠ¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸ (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ì „ì²˜ë¦¬, ì¦ê°• ì—†ìŒ)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet í‘œì¤€\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"ðŸŽ¨ í…ŒìŠ¤íŠ¸ ë³€í™˜ íŒŒì´í”„ë¼ì¸:\")\n",
        "print(\"   1. Resize: 224Ã—224 (BICUBIC)\")\n",
        "print(\"   2. ToTensor: [0,255] â†’ [0,1]\")\n",
        "print(\"   3. Normalize: ImageNet í‘œì¤€\")\n",
        "print(\"   âš ï¸ ì¦ê°• ì—†ìŒ (ì¼ê´€ëœ ì˜ˆì¸¡ì„ ìœ„í•´)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸:\n",
            "âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸ ì™„ë£Œ\n",
            "ðŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ:\n",
            "   ì´ ìƒ˜í”Œ ìˆ˜: 95,006ê°œ\n",
            "   CSV ì»¬ëŸ¼: ['ID', 'img_path']\n",
            "âœ… ì´ë¯¸ì§€ ê²½ë¡œ í™•ì¸ ì™„ë£Œ\n",
            "\n",
            "ðŸ“Š í…ŒìŠ¤íŠ¸ DataLoader ì„¤ì •:\n",
            "   ë°°ì¹˜ í¬ê¸°: 32\n",
            "   ì „ì²´ ë°°ì¹˜ ìˆ˜: 2,969ê°œ\n",
            "   ì „ì²´ ìƒ˜í”Œ ìˆ˜: 95,006ê°œ\n",
            "\n",
            "ðŸ”® ì¶”ë¡  ì‹¤í–‰ ì¤‘...\n",
            "   ì§„í–‰ë¥ : 3.4% (100/2,969)\n",
            "   ì§„í–‰ë¥ : 6.7% (200/2,969)\n",
            "   ì§„í–‰ë¥ : 10.1% (300/2,969)\n",
            "   ì§„í–‰ë¥ : 13.5% (400/2,969)\n",
            "   ì§„í–‰ë¥ : 16.8% (500/2,969)\n",
            "   ì§„í–‰ë¥ : 20.2% (600/2,969)\n",
            "   ì§„í–‰ë¥ : 23.6% (700/2,969)\n",
            "   ì§„í–‰ë¥ : 26.9% (800/2,969)\n",
            "   ì§„í–‰ë¥ : 30.3% (900/2,969)\n",
            "   ì§„í–‰ë¥ : 33.7% (1,000/2,969)\n",
            "   ì§„í–‰ë¥ : 37.0% (1,100/2,969)\n",
            "   ì§„í–‰ë¥ : 40.4% (1,200/2,969)\n",
            "   ì§„í–‰ë¥ : 43.8% (1,300/2,969)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ðŸš€ ì¶”ë¡  ì‹¤í–‰ ë° ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "# ============================================================================\n",
        "\n",
        "def run_inference_and_create_submission():\n",
        "    \"\"\"ì¶”ë¡  ì‹¤í–‰ ë° ì œì¶œ íŒŒì¼ ìƒì„±\"\"\"\n",
        "    \n",
        "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¡´ìž¬ í™•ì¸\n",
        "    print(\"ðŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸:\")\n",
        "    if not os.path.exists(TEST_CSV_PATH):\n",
        "        print(f\"âŒ test.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {TEST_CSV_PATH}\")\n",
        "        return None\n",
        "    if not os.path.exists(TEST_PATH):\n",
        "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {TEST_PATH}\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸ ì™„ë£Œ\")\n",
        "    \n",
        "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±\n",
        "    try:\n",
        "        test_dataset = TestDataset(\n",
        "            test_csv_path=TEST_CSV_PATH,\n",
        "            test_dir=TEST_PATH,\n",
        "            transform=test_transform\n",
        "        )\n",
        "        \n",
        "        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œë” ìƒì„±\n",
        "        test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=32,  # ì¶”ë¡ ìš©ì´ë¯€ë¡œ í° ë°°ì¹˜ ì‚¬ì´ì¦ˆ ì‚¬ìš©\n",
        "            shuffle=False,  # ìˆœì„œ ìœ ì§€ í•„ìš”\n",
        "            num_workers=0,  # Windows í˜¸í™˜ì„±\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "        \n",
        "        print(f\"\\nðŸ“Š í…ŒìŠ¤íŠ¸ DataLoader ì„¤ì •:\")\n",
        "        print(f\"   ë°°ì¹˜ í¬ê¸°: {test_dataloader.batch_size}\")\n",
        "        print(f\"   ì „ì²´ ë°°ì¹˜ ìˆ˜: {len(test_dataloader):,}ê°œ\")\n",
        "        print(f\"   ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(test_dataset):,}ê°œ\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"âŒ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
        "        return None\n",
        "    \n",
        "    # ëª¨ë¸ í™•ì¸\n",
        "    if model_loader.model is None:\n",
        "        print(\"âŒ ë¡œë“œëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "        return None\n",
        "    \n",
        "    # ì¶”ë¡  ì‹¤í–‰\n",
        "    print(f\"\\nðŸ”® ì¶”ë¡  ì‹¤í–‰ ì¤‘...\")\n",
        "    model_loader.model.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    ids = []\n",
        "    confidences = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_dataloader):\n",
        "            # ë°ì´í„° GPUë¡œ ì´ë™\n",
        "            images = batch['image'].to(device)\n",
        "            batch_ids = batch['id']\n",
        "            \n",
        "            # ëª¨ë¸ ì˜ˆì¸¡\n",
        "            outputs = model_loader.model(images)\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            \n",
        "            # ì˜ˆì¸¡ í´ëž˜ìŠ¤ ë° ì‹ ë¢°ë„\n",
        "            max_probs, predicted_classes = torch.max(probabilities, dim=1)\n",
        "            \n",
        "            # ê²°ê³¼ ì €ìž¥\n",
        "            predictions.extend(predicted_classes.cpu().numpy())\n",
        "            confidences.extend(max_probs.cpu().numpy())\n",
        "            ids.extend(batch_ids)\n",
        "            \n",
        "            # ì§„í–‰ë¥  ì¶œë ¥\n",
        "            if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(test_dataloader):\n",
        "                progress = (batch_idx + 1) / len(test_dataloader) * 100\n",
        "                print(f\"   ì§„í–‰ë¥ : {progress:.1f}% ({batch_idx + 1:,}/{len(test_dataloader):,})\")\n",
        "    \n",
        "    print(f\"âœ… ì¶”ë¡  ì™„ë£Œ!\")\n",
        "    print(f\"   ì´ ì˜ˆì¸¡ ìˆ˜: {len(predictions):,}ê°œ\")\n",
        "    print(f\"   í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences):.3f}\")\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "    print(f\"\\nðŸ“„ ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í´ëž˜ìŠ¤ëª…ìœ¼ë¡œ ë³€í™˜\n",
        "    predicted_classes = [idx_to_class[pred] for pred in predictions]\n",
        "    \n",
        "    # ì œì¶œ íŒŒì¼ ìƒì„±\n",
        "    submission_df = pd.DataFrame({\n",
        "        'ID': ids,\n",
        "        'rock_type': predicted_classes\n",
        "    })\n",
        "    \n",
        "    # ì •ë ¬ (ID ìˆœì„œëŒ€ë¡œ)\n",
        "    submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
        "    \n",
        "    # íŒŒì¼ëª…ì— íƒ€ìž„ìŠ¤íƒ¬í”„ ì¶”ê°€\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    model_name_short = model_loader.model_info['model_name'].split('.')[0]\n",
        "    submission_filename = f\"submission_{model_name_short}_{timestamp}.csv\"\n",
        "    submission_path = RESULTS_DIR / submission_filename\n",
        "    \n",
        "    # íŒŒì¼ ì €ìž¥\n",
        "    submission_df.to_csv(submission_path, index=False)\n",
        "    \n",
        "    print(f\"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ: {submission_path}\")\n",
        "    print(f\"   ì´ ìƒ˜í”Œ ìˆ˜: {len(submission_df):,}ê°œ\")\n",
        "    print(f\"   íŒŒì¼ í¬ê¸°: {os.path.getsize(submission_path) / 1024:.1f} KB\")\n",
        "    \n",
        "    # ì˜ˆì¸¡ ë¶„í¬ í™•ì¸\n",
        "    print(f\"\\nðŸ·ï¸ ì˜ˆì¸¡ í´ëž˜ìŠ¤ ë¶„í¬:\")\n",
        "    class_counts = submission_df['rock_type'].value_counts()\n",
        "    for rock_type, count in class_counts.items():\n",
        "        percentage = count / len(submission_df) * 100\n",
        "        print(f\"   {rock_type}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
        "    \n",
        "    return {\n",
        "        'submission_df': submission_df,\n",
        "        'submission_path': submission_path,\n",
        "        'predictions': predictions,\n",
        "        'confidences': confidences,\n",
        "        'timestamp': timestamp\n",
        "    }\n",
        "\n",
        "# ì¶”ë¡  ë° ì œì¶œ íŒŒì¼ ìƒì„± ì‹¤í–‰\n",
        "if model_loader.model is not None:\n",
        "    inference_results = run_inference_and_create_submission()\n",
        "    if inference_results:\n",
        "        print(f\"\\nðŸŽ¯ ì¶”ë¡  ìž‘ì—… ì™„ë£Œ!\")\n",
        "        print(f\"   ì œì¶œ íŒŒì¼: {inference_results['submission_path']}\")\n",
        "else:\n",
        "    print(\"âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ ì¶”ë¡ ì„ ì‹¤í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "    inference_results = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ðŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_and_visualize_results(inference_results):\n",
        "    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë¶„ì„ ë° ì‹œê°í™”\"\"\"\n",
        "    \n",
        "    if inference_results is None:\n",
        "        print(\"âŒ ë¶„ì„í•  ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "        return\n",
        "    \n",
        "    submission_df = inference_results['submission_df']\n",
        "    confidences = np.array(inference_results['confidences'])\n",
        "    predictions = inference_results['predictions']\n",
        "    timestamp = inference_results['timestamp']\n",
        "    \n",
        "    print(\"ðŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìƒì„¸ ë¶„ì„\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # ì‹ ë¢°ë„ ë¶„ì„\n",
        "    print(f\"ðŸŽ¯ ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„ì„:\")\n",
        "    print(f\"   í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences):.3f}\")\n",
        "    print(f\"   í‘œì¤€íŽ¸ì°¨: {np.std(confidences):.3f}\")\n",
        "    print(f\"   ìµœê³  ì‹ ë¢°ë„: {np.max(confidences):.3f}\")\n",
        "    print(f\"   ìµœì € ì‹ ë¢°ë„: {np.min(confidences):.3f}\")\n",
        "    \n",
        "    # ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬\n",
        "    confidence_ranges = [\n",
        "        (0.9, 1.0, \"ë§¤ìš° ë†’ìŒ\"),\n",
        "        (0.8, 0.9, \"ë†’ìŒ\"),\n",
        "        (0.7, 0.8, \"ë³´í†µ\"),\n",
        "        (0.6, 0.7, \"ë‚®ìŒ\"),\n",
        "        (0.0, 0.6, \"ë§¤ìš° ë‚®ìŒ\")\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\nðŸ“ˆ ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬:\")\n",
        "    for min_conf, max_conf, label in confidence_ranges:\n",
        "        count = np.sum((confidences >= min_conf) & (confidences < max_conf))\n",
        "        percentage = count / len(confidences) * 100\n",
        "        print(f\"   {label} ({min_conf:.1f}-{max_conf:.1f}): {count:,}ê°œ ({percentage:.1f}%)\")\n",
        "    \n",
        "    # í´ëž˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬ ì‹œê°í™”\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    \n",
        "    # 1. í´ëž˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬\n",
        "    plt.subplot(2, 3, 1)\n",
        "    class_counts = submission_df['rock_type'].value_counts()\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(class_counts)))\n",
        "    \n",
        "    bars = plt.bar(range(len(class_counts)), class_counts.values, color=colors)\n",
        "    plt.xticks(range(len(class_counts)), class_counts.index, rotation=45, ha='right')\n",
        "    plt.title('ì˜ˆì¸¡ í´ëž˜ìŠ¤ë³„ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('ì˜ˆì¸¡ ê°œìˆ˜')\n",
        "    \n",
        "    # ë§‰ëŒ€ ìœ„ì— ê°œìˆ˜ í‘œì‹œ\n",
        "    for bar, count in zip(bars, class_counts.values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n",
        "                f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 2. ì‹ ë¢°ë„ ížˆìŠ¤í† ê·¸ëž¨\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.hist(confidences, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    plt.axvline(np.mean(confidences), color='red', linestyle='--', \n",
        "                label=f'í‰ê· : {np.mean(confidences):.3f}')\n",
        "    plt.title('ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('ì‹ ë¢°ë„')\n",
        "    plt.ylabel('ë¹ˆë„')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. í´ëž˜ìŠ¤ë³„ í‰ê·  ì‹ ë¢°ë„\n",
        "    plt.subplot(2, 3, 3)\n",
        "    \n",
        "    # í´ëž˜ìŠ¤ë³„ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°\n",
        "    class_confidences = {}\n",
        "    for i, pred_class in enumerate(predictions):\n",
        "        class_name = idx_to_class[pred_class]\n",
        "        if class_name not in class_confidences:\n",
        "            class_confidences[class_name] = []\n",
        "        class_confidences[class_name].append(confidences[i])\n",
        "    \n",
        "    avg_confidences = {cls: np.mean(confs) for cls, confs in class_confidences.items()}\n",
        "    \n",
        "    sorted_classes = sorted(avg_confidences.items(), key=lambda x: x[1], reverse=True)\n",
        "    classes, avg_confs = zip(*sorted_classes)\n",
        "    \n",
        "    bars = plt.bar(range(len(classes)), avg_confs, color=colors[:len(classes)])\n",
        "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
        "    plt.title('í´ëž˜ìŠ¤ë³„ í‰ê·  ì‹ ë¢°ë„', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('í‰ê·  ì‹ ë¢°ë„')\n",
        "    plt.ylim(0, 1)\n",
        "    \n",
        "    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ\n",
        "    for bar, conf in zip(bars, avg_confs):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{conf:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 4. ì‹ ë¢°ë„ vs í´ëž˜ìŠ¤ ë°•ìŠ¤í”Œë¡¯\n",
        "    plt.subplot(2, 3, 4)\n",
        "    \n",
        "    # ë°•ìŠ¤í”Œë¡¯ ë°ì´í„° ì¤€ë¹„\n",
        "    box_data = [class_confidences[cls] for cls in sorted(class_confidences.keys())]\n",
        "    box_labels = sorted(class_confidences.keys())\n",
        "    \n",
        "    plt.boxplot(box_data, labels=box_labels)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('í´ëž˜ìŠ¤ë³„ ì‹ ë¢°ë„ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('ì‹ ë¢°ë„')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬\n",
        "    plt.subplot(2, 3, 5)\n",
        "    ranges = ['ë§¤ìš° ë‚®ìŒ', 'ë‚®ìŒ', 'ë³´í†µ', 'ë†’ìŒ', 'ë§¤ìš° ë†’ìŒ']\n",
        "    range_counts = []\n",
        "    for min_conf, max_conf, _ in confidence_ranges:\n",
        "        count = np.sum((confidences >= min_conf) & (confidences < max_conf))\n",
        "        range_counts.append(count)\n",
        "    \n",
        "    plt.pie(range_counts, labels=ranges, autopct='%1.1f%%', colors=plt.cm.Pastel1.colors)\n",
        "    plt.title('ì‹ ë¢°ë„ êµ¬ê°„ë³„ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # 6. í´ëž˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "    plt.title('ì˜ˆì¸¡ í´ëž˜ìŠ¤ ë¶„í¬', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # ê²°ê³¼ ì €ìž¥\n",
        "    analysis_plot_path = RESULTS_DIR / f\"prediction_analysis_{timestamp}.png\"\n",
        "    plt.savefig(analysis_plot_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\nðŸ“Š ë¶„ì„ ì°¨íŠ¸ ì €ìž¥: {analysis_plot_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return class_confidences, avg_confidences\n",
        "\n",
        "def generate_final_report(inference_results):\n",
        "    \"\"\"ìµœì¢… ì¶”ë¡  ë¦¬í¬íŠ¸ ìƒì„±\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"ðŸŽ¯ ê±´ì„¤ìš© ìžê°ˆ ì•”ì„ ë¶„ë¥˜ AI - ì¶”ë¡  ì™„ë£Œ ë¦¬í¬íŠ¸\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # ëª¨ë¸ ì •ë³´\n",
        "    if model_loader.model_info:\n",
        "        print(f\"\\nðŸ¤– ì‚¬ìš©ëœ ëª¨ë¸:\")\n",
        "        print(f\"   ì•„í‚¤í…ì²˜: {model_loader.model_info['model_name']}\")\n",
        "        print(f\"   ì²´í¬í¬ì¸íŠ¸: {os.path.basename(model_loader.model_info['model_path'])}\")\n",
        "        print(f\"   ìµœê³  ì„±ëŠ¥: {model_loader.model_info['best_score']}\")\n",
        "        print(f\"   ì´ íŒŒë¼ë¯¸í„°: {model_loader.model_info['total_params']:,}ê°œ\")\n",
        "    \n",
        "    # ì¶”ë¡  ê²°ê³¼\n",
        "    if inference_results:\n",
        "        submission_df = inference_results['submission_df']\n",
        "        confidences = inference_results['confidences']\n",
        "        \n",
        "        print(f\"\\nðŸ“Š ì¶”ë¡  ê²°ê³¼:\")\n",
        "        print(f\"   ì´ ì˜ˆì¸¡ ìƒ˜í”Œ: {len(submission_df):,}ê°œ\")\n",
        "        print(f\"   í‰ê·  ì‹ ë¢°ë„: {np.mean(confidences):.3f}\")\n",
        "        print(f\"   ì‹ ë¢°ë„ ë²”ìœ„: {np.min(confidences):.3f} - {np.max(confidences):.3f}\")\n",
        "        \n",
        "        # ì œì¶œ íŒŒì¼ ì •ë³´\n",
        "        print(f\"\\nðŸ“„ ì œì¶œ íŒŒì¼:\")\n",
        "        submission_path = inference_results['submission_path']\n",
        "        print(f\"   íŒŒì¼ëª…: {os.path.basename(submission_path)}\")\n",
        "        print(f\"   ê²½ë¡œ: {submission_path}\")\n",
        "        print(f\"   ìƒ˜í”Œ ìˆ˜: {len(submission_df):,}ê°œ\")\n",
        "        print(f\"   íŒŒì¼ í¬ê¸°: {os.path.getsize(submission_path) / 1024:.1f} KB\")\n",
        "        \n",
        "        # ì˜ˆì¸¡ í´ëž˜ìŠ¤ ë¶„í¬\n",
        "        print(f\"\\nðŸ·ï¸ ì˜ˆì¸¡ í´ëž˜ìŠ¤ ë¶„í¬:\")\n",
        "        class_counts = submission_df['rock_type'].value_counts()\n",
        "        for rock_type, count in class_counts.items():\n",
        "            percentage = count / len(submission_df) * 100\n",
        "            print(f\"   {rock_type}: {count:,}ê°œ ({percentage:.1f}%)\")\n",
        "        \n",
        "        # ìƒì„±ëœ íŒŒì¼ë“¤\n",
        "        print(f\"\\nðŸ“ ìƒì„±ëœ íŒŒì¼ë“¤:\")\n",
        "        result_files = list(RESULTS_DIR.glob(f\"*{inference_results['timestamp']}*\"))\n",
        "        for file_path in result_files:\n",
        "            print(f\"   ðŸ“„ {file_path.name}\")\n",
        "        \n",
        "        print(f\"\\nâœ… ì¶”ë¡  ìž‘ì—… ì™„ë£Œ!\")\n",
        "        print(f\"   ë‹¤ìŒ ë‹¨ê³„: ì œì¶œ íŒŒì¼ì„ ëŒ€íšŒ ì‚¬ì´íŠ¸ì— ì—…ë¡œë“œ\")\n",
        "        print(f\"   ê²½ë¡œ: {submission_path}\")\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "\n",
        "# ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ì‹¤í–‰\n",
        "if inference_results is not None:\n",
        "    print(\"\\nðŸ” ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„ ì‹œìž‘...\")\n",
        "    class_confidences, avg_confidences = analyze_and_visualize_results(inference_results)\n",
        "    generate_final_report(inference_results)\n",
        "else:\n",
        "    print(\"âŒ ë¶„ì„í•  ì¶”ë¡  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤!\")\n",
        "    print(\"   ìœ„ì˜ ì…€ì„ ì‹¤í–‰í•˜ì—¬ ì¶”ë¡ ì„ ì™„ë£Œí•˜ì„¸ìš”.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "yolo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
