{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 🔮 건설용 자갈 암석 분류 AI - 추론 및 제출 파일 생성\n",
        "\n",
        "## 📋 목표\n",
        "- 학습된 모델을 사용하여 테스트 데이터 예측\n",
        "- 대회 제출 파일 생성 (sample_submission.csv 형식)\n",
        "- 예측 결과 분석 및 품질 검증\n",
        "\n",
        "## 🎯 진행 과정\n",
        "1. 학습된 모델 로드\n",
        "2. 테스트 데이터 전처리 파이프라인\n",
        "3. 배치 단위 추론 실행\n",
        "4. 제출 파일 생성\n",
        "5. 예측 결과 분석\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\wang\\anaconda3\\envs\\yolo\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ 한글 폰트 설정 완료: Malgun Gothic\n",
            "🔮 건설용 자갈 암석 분류 AI - 추론 시작!\n",
            "PyTorch 버전: 2.2.2+cu121\n",
            "CUDA 사용 가능: True\n",
            "GPU: NVIDIA GeForce RTX 4070\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 📦 필수 라이브러리 및 설정\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "# 데이터 처리\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# 딥러닝\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import timm\n",
        "\n",
        "# 시각화\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import font_manager\n",
        "\n",
        "# 경고 억제\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정\n",
        "def setup_korean_font():\n",
        "    \"\"\"Windows 환경에서 한글 폰트 설정\"\"\"\n",
        "    font_names = ['Malgun Gothic', 'NanumGothic', 'DejaVu Sans']\n",
        "    \n",
        "    for font_name in font_names:\n",
        "        try:\n",
        "            font_path = None\n",
        "            for font in font_manager.fontManager.ttflist:\n",
        "                if font_name.lower() in font.name.lower():\n",
        "                    font_path = font.fname\n",
        "                    break\n",
        "            \n",
        "            if font_path:\n",
        "                plt.rcParams['font.family'] = font_name\n",
        "                plt.rcParams['axes.unicode_minus'] = False\n",
        "                print(f\"✅ 한글 폰트 설정 완료: {font_name}\")\n",
        "                return True\n",
        "        except:\n",
        "            continue\n",
        "    \n",
        "    print(\"⚠️ 한글 폰트 설정 실패 - 기본 폰트 사용\")\n",
        "    return False\n",
        "\n",
        "setup_korean_font()\n",
        "\n",
        "# 시드 고정\n",
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print(\"🔮 건설용 자갈 암석 분류 AI - 추론 시작!\")\n",
        "print(f\"PyTorch 버전: {torch.__version__}\")\n",
        "print(f\"CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 경로 설정 완료:\n",
            "테스트 데이터: D:\\data\\stones\\open\\test\n",
            "테스트 CSV: D:\\data\\stones\\open\\test.csv\n",
            "모델 저장: ..\\models\n",
            "결과 저장: ..\\results\n",
            "\n",
            "🏷️ 클래스 정보:\n",
            "클래스 수: 7\n",
            "클래스 목록: ['Andesite', 'Basalt', 'Etc', 'Gneiss', 'Granite', 'Mud_Sandstone', 'Weathered_Rock']\n",
            "\n",
            "💻 연산 장치: cuda\n",
            "GPU 메모리: 12.0 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 🔧 경로 및 설정 로드\n",
        "# ============================================================================\n",
        "\n",
        "# 기본 경로 설정\n",
        "BASE_PATH = r\"D:\\data\\stones\\open\"\n",
        "TEST_PATH = os.path.join(BASE_PATH, \"test\")\n",
        "TEST_CSV_PATH = os.path.join(BASE_PATH, \"test.csv\")\n",
        "SUBMISSION_PATH = os.path.join(BASE_PATH, \"sample_submission.csv\")\n",
        "\n",
        "# 프로젝트 경로\n",
        "MODEL_DIR = Path(\"../models\")\n",
        "EXPERIMENT_DIR = Path(\"../experiments\")\n",
        "RESULTS_DIR = Path(\"../results\")\n",
        "RESULTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# 실험 설정 로드\n",
        "config_path = EXPERIMENT_DIR / \"experiment_config.json\"\n",
        "with open(config_path, 'r', encoding='utf-8') as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# 클래스 정보\n",
        "CLASS_NAMES = config['project_info']['class_names']\n",
        "NUM_CLASSES = config['project_info']['num_classes']\n",
        "class_to_idx = {cls: i for i, cls in enumerate(CLASS_NAMES)}\n",
        "idx_to_class = {i: cls for cls, i in class_to_idx.items()}\n",
        "\n",
        "# 디바이스 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(\"📂 경로 설정 완료:\")\n",
        "print(f\"테스트 데이터: {TEST_PATH}\")\n",
        "print(f\"테스트 CSV: {TEST_CSV_PATH}\")\n",
        "print(f\"모델 저장: {MODEL_DIR}\")\n",
        "print(f\"결과 저장: {RESULTS_DIR}\")\n",
        "\n",
        "print(f\"\\n🏷️ 클래스 정보:\")\n",
        "print(f\"클래스 수: {NUM_CLASSES}\")\n",
        "print(f\"클래스 목록: {CLASS_NAMES}\")\n",
        "\n",
        "print(f\"\\n💻 연산 장치: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3\n",
        "    print(f\"GPU 메모리: {gpu_memory:.1f} GB\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 사용 가능한 모델:\n",
            "1. EfficientNetV2-S_quick_baseline\n",
            "   크기: 232.3 MB\n",
            "   수정: 2025-08-23 04:55:16\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 🏭 모델 팩토리 및 로더\n",
        "# ============================================================================\n",
        "\n",
        "class ModelFactory:\n",
        "    \"\"\"다양한 모델 아키텍처를 생성하는 팩토리 클래스\"\"\"\n",
        "    \n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=7, pretrained=False):\n",
        "        \"\"\"모델 생성\"\"\"\n",
        "        try:\n",
        "            # timm을 통한 모델 생성\n",
        "            model = timm.create_model(\n",
        "                model_name,\n",
        "                pretrained=pretrained,\n",
        "                num_classes=num_classes\n",
        "            )\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            print(f\"❌ 모델 생성 실패 ({model_name}): {e}\")\n",
        "            return None\n",
        "\n",
        "class ModelLoader:\n",
        "    \"\"\"학습된 모델을 로드하는 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "        self.model = None\n",
        "        self.model_info = None\n",
        "    \n",
        "    def load_model(self, model_path, model_name):\n",
        "        \"\"\"저장된 모델 로드\"\"\"\n",
        "        try:\n",
        "            print(f\"📂 모델 로드 중: {model_path}\")\n",
        "            \n",
        "            # 체크포인트 로드\n",
        "            checkpoint = torch.load(model_path, map_location=self.device)\n",
        "            \n",
        "            # 모델 생성\n",
        "            self.model = ModelFactory.create_model(model_name, NUM_CLASSES)\n",
        "            if self.model is None:\n",
        "                return False\n",
        "            \n",
        "            # 가중치 로드\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.model.to(self.device)\n",
        "            self.model.eval()\n",
        "            \n",
        "            # 모델 정보 저장\n",
        "            self.model_info = {\n",
        "                'model_path': str(model_path),\n",
        "                'model_name': model_name,\n",
        "                'best_score': checkpoint.get('best_score', 'N/A'),\n",
        "                'epoch': checkpoint.get('epoch', 'N/A'),\n",
        "                'total_params': sum(p.numel() for p in self.model.parameters())\n",
        "            }\n",
        "            \n",
        "            print(f\"✅ 모델 로드 완료!\")\n",
        "            print(f\"   모델 아키텍처: {model_name}\")\n",
        "            print(f\"   최고 성능: {self.model_info['best_score']}\")\n",
        "            print(f\"   총 파라미터: {self.model_info['total_params']:,}개\")\n",
        "            \n",
        "            return True\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 모델 로드 실패: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_available_models(self):\n",
        "        \"\"\"사용 가능한 모델 목록 반환\"\"\"\n",
        "        model_files = list(MODEL_DIR.glob(\"*.pth\"))\n",
        "        \n",
        "        available = []\n",
        "        for model_file in model_files:\n",
        "            # 파일명에서 모델 정보 추출\n",
        "            model_info = {\n",
        "                'path': model_file,\n",
        "                'name': model_file.stem,\n",
        "                'size_mb': model_file.stat().st_size / (1024 * 1024),\n",
        "                'modified': datetime.fromtimestamp(model_file.stat().st_mtime)\n",
        "            }\n",
        "            available.append(model_info)\n",
        "        \n",
        "        # 수정 시간순 정렬 (최신 순)\n",
        "        available.sort(key=lambda x: x['modified'], reverse=True)\n",
        "        \n",
        "        return available\n",
        "\n",
        "# 사용 가능한 모델 확인\n",
        "model_loader = ModelLoader(device)\n",
        "available_models = model_loader.get_available_models()\n",
        "\n",
        "print(\"🔍 사용 가능한 모델:\")\n",
        "if available_models:\n",
        "    for i, model_info in enumerate(available_models, 1):\n",
        "        print(f\"{i}. {model_info['name']}\")\n",
        "        print(f\"   크기: {model_info['size_mb']:.1f} MB\")\n",
        "        print(f\"   수정: {model_info['modified'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "else:\n",
        "    print(\"❌ 사용 가능한 모델이 없습니다!\")\n",
        "    print(\"   먼저 03_model_training.ipynb에서 모델을 학습하세요.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📂 선택된 모델: EfficientNetV2-S_quick_baseline\n",
            "   경로: ..\\models\\EfficientNetV2-S_quick_baseline.pth\n",
            "   크기: 232.3 MB\n",
            "   아키텍처: tf_efficientnetv2_s.in21k_ft_in1k\n",
            "📂 모델 로드 중: ..\\models\\EfficientNetV2-S_quick_baseline.pth\n",
            "✅ 모델 로드 완료!\n",
            "   모델 아키텍처: tf_efficientnetv2_s.in21k_ft_in1k\n",
            "   최고 성능: 0.7997457306490847\n",
            "   총 파라미터: 20,186,455개\n",
            "\n",
            "🎯 모델 준비 완료!\n",
            "   추론 준비 상태: ✅\n",
            "   GPU 사용: True\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 🔮 학습된 모델 로드\n",
        "# ============================================================================\n",
        "\n",
        "if not available_models:\n",
        "    print(\"❌ 로드할 모델이 없습니다!\")\n",
        "    print(\"   먼저 03_model_training.ipynb에서 모델을 학습하세요.\")\n",
        "else:\n",
        "    # 가장 최신 모델 선택\n",
        "    latest_model = available_models[0]\n",
        "    model_path = latest_model['path']\n",
        "    \n",
        "    print(f\"📂 선택된 모델: {latest_model['name']}\")\n",
        "    print(f\"   경로: {model_path}\")\n",
        "    print(f\"   크기: {latest_model['size_mb']:.1f} MB\")\n",
        "    \n",
        "    # 모델명 추출 (파일명에서)\n",
        "    if \"EfficientNetV2-S\" in latest_model['name']:\n",
        "        model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"\n",
        "    elif \"EfficientNetV2-M\" in latest_model['name']:\n",
        "        model_name = \"tf_efficientnetv2_m.in21k_ft_in1k\"\n",
        "    elif \"ConvNeXt\" in latest_model['name']:\n",
        "        model_name = \"convnext_tiny.fb_in22k_ft_in1k\"\n",
        "    elif \"ViT\" in latest_model['name']:\n",
        "        model_name = \"vit_tiny_patch16_224.augreg_in21k_ft_in1k\"\n",
        "    else:\n",
        "        model_name = \"tf_efficientnetv2_s.in21k_ft_in1k\"  # 기본값\n",
        "    \n",
        "    print(f\"   아키텍처: {model_name}\")\n",
        "    \n",
        "    # 모델 로드\n",
        "    success = model_loader.load_model(model_path, model_name)\n",
        "    \n",
        "    if success:\n",
        "        print(f\"\\n🎯 모델 준비 완료!\")\n",
        "        print(f\"   추론 준비 상태: ✅\")\n",
        "        print(f\"   GPU 사용: {next(model_loader.model.parameters()).is_cuda}\")\n",
        "    else:\n",
        "        print(f\"\\n❌ 모델 로드 실패!\")\n",
        "        model_loader.model = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎨 테스트 변환 파이프라인:\n",
            "   1. Resize: 224×224 (BICUBIC)\n",
            "   2. ToTensor: [0,255] → [0,1]\n",
            "   3. Normalize: ImageNet 표준\n",
            "   ⚠️ 증강 없음 (일관된 예측을 위해)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 📊 테스트 데이터셋 및 추론 파이프라인\n",
        "# ============================================================================\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    \"\"\"테스트 데이터를 위한 데이터셋 클래스\"\"\"\n",
        "    \n",
        "    def __init__(self, test_csv_path, test_dir, transform=None):\n",
        "        self.test_df = pd.read_csv(test_csv_path)\n",
        "        self.test_dir = test_dir\n",
        "        self.transform = transform\n",
        "        \n",
        "        print(f\"📊 테스트 데이터셋 생성 완료:\")\n",
        "        print(f\"   총 샘플 수: {len(self.test_df):,}개\")\n",
        "        print(f\"   CSV 컬럼: {list(self.test_df.columns)}\")\n",
        "        \n",
        "        # 샘플 경로 확인\n",
        "        sample_img_path = self.test_df.iloc[0]['img_path']\n",
        "        if sample_img_path.startswith('./'):\n",
        "            # ./를 제거하고 BASE_PATH와 조인\n",
        "            relative_path = sample_img_path[2:]\n",
        "            base_path = os.path.dirname(self.test_dir)\n",
        "            sample_path = os.path.join(base_path, relative_path)\n",
        "        else:\n",
        "            sample_path = os.path.join(self.test_dir, sample_img_path)\n",
        "            \n",
        "        if os.path.exists(sample_path):\n",
        "            print(f\"✅ 이미지 경로 확인 완료\")\n",
        "        else:\n",
        "            print(f\"❌ 이미지 경로 오류: {sample_path}\")\n",
        "            print(f\"   원본 img_path: {sample_img_path}\")\n",
        "            print(f\"   test_dir: {self.test_dir}\")\n",
        "            print(f\"   base_path: {os.path.dirname(self.test_dir)}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.test_df)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # 이미지 정보 가져오기\n",
        "        img_id = self.test_df.iloc[idx]['ID']\n",
        "        img_path = self.test_df.iloc[idx]['img_path']\n",
        "        \n",
        "        # 이미지 로드 (img_path가 이미 ./test/를 포함하므로 BASE_PATH 사용)\n",
        "        # img_path 형태: \"./test/TEST_00000.jpg\"\n",
        "        if img_path.startswith('./'):\n",
        "            # ./를 제거하고 BASE_PATH와 조인\n",
        "            relative_path = img_path[2:]  # \"./test/TEST_00000.jpg\" -> \"test/TEST_00000.jpg\"\n",
        "            base_path = os.path.dirname(self.test_dir)  # D:\\data\\stones\\open\\test -> D:\\data\\stones\\open\n",
        "            full_path = os.path.join(base_path, relative_path)\n",
        "        else:\n",
        "            # 기존 방식 (혹시 경로 형태가 다를 경우를 위한 fallback)\n",
        "            full_path = os.path.join(self.test_dir, img_path)\n",
        "        \n",
        "        try:\n",
        "            image = Image.open(full_path).convert('RGB')\n",
        "            \n",
        "            # 변환 적용\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return {\n",
        "                'image': image,\n",
        "                'id': img_id,\n",
        "                'path': img_path\n",
        "            }\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"❌ 이미지 로드 실패 ({img_path}): {e}\")\n",
        "            print(f\"   시도한 경로: {full_path}\")\n",
        "            # 빈 이미지 반환\n",
        "            dummy_image = torch.zeros(3, 224, 224)\n",
        "            return {\n",
        "                'image': dummy_image,\n",
        "                'id': img_id,\n",
        "                'path': img_path\n",
        "            }\n",
        "\n",
        "# 테스트 변환 파이프라인 (학습 시와 동일한 전처리, 증강 없음)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "        mean=[0.485, 0.456, 0.406],  # ImageNet 표준\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])\n",
        "\n",
        "print(\"🎨 테스트 변환 파이프라인:\")\n",
        "print(\"   1. Resize: 224×224 (BICUBIC)\")\n",
        "print(\"   2. ToTensor: [0,255] → [0,1]\")\n",
        "print(\"   3. Normalize: ImageNet 표준\")\n",
        "print(\"   ⚠️ 증강 없음 (일관된 예측을 위해)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🔍 테스트 데이터 확인:\n",
            "✅ 테스트 데이터 확인 완료\n",
            "📊 테스트 데이터셋 생성 완료:\n",
            "   총 샘플 수: 95,006개\n",
            "   CSV 컬럼: ['ID', 'img_path']\n",
            "✅ 이미지 경로 확인 완료\n",
            "\n",
            "📊 테스트 DataLoader 설정:\n",
            "   배치 크기: 32\n",
            "   전체 배치 수: 2,969개\n",
            "   전체 샘플 수: 95,006개\n",
            "\n",
            "🔮 추론 실행 중...\n",
            "   진행률: 3.4% (100/2,969)\n",
            "   진행률: 6.7% (200/2,969)\n",
            "   진행률: 10.1% (300/2,969)\n",
            "   진행률: 13.5% (400/2,969)\n",
            "   진행률: 16.8% (500/2,969)\n",
            "   진행률: 20.2% (600/2,969)\n",
            "   진행률: 23.6% (700/2,969)\n",
            "   진행률: 26.9% (800/2,969)\n",
            "   진행률: 30.3% (900/2,969)\n",
            "   진행률: 33.7% (1,000/2,969)\n",
            "   진행률: 37.0% (1,100/2,969)\n",
            "   진행률: 40.4% (1,200/2,969)\n",
            "   진행률: 43.8% (1,300/2,969)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 🚀 추론 실행 및 제출 파일 생성\n",
        "# ============================================================================\n",
        "\n",
        "def run_inference_and_create_submission():\n",
        "    \"\"\"추론 실행 및 제출 파일 생성\"\"\"\n",
        "    \n",
        "    # 테스트 데이터 존재 확인\n",
        "    print(\"🔍 테스트 데이터 확인:\")\n",
        "    if not os.path.exists(TEST_CSV_PATH):\n",
        "        print(f\"❌ test.csv 파일이 없습니다: {TEST_CSV_PATH}\")\n",
        "        return None\n",
        "    if not os.path.exists(TEST_PATH):\n",
        "        print(f\"❌ 테스트 이미지 디렉토리가 없습니다: {TEST_PATH}\")\n",
        "        return None\n",
        "    \n",
        "    print(f\"✅ 테스트 데이터 확인 완료\")\n",
        "    \n",
        "    # 테스트 데이터셋 생성\n",
        "    try:\n",
        "        test_dataset = TestDataset(\n",
        "            test_csv_path=TEST_CSV_PATH,\n",
        "            test_dir=TEST_PATH,\n",
        "            transform=test_transform\n",
        "        )\n",
        "        \n",
        "        # 테스트 데이터로더 생성\n",
        "        test_dataloader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=32,  # 추론용이므로 큰 배치 사이즈 사용\n",
        "            shuffle=False,  # 순서 유지 필요\n",
        "            num_workers=0,  # Windows 호환성\n",
        "            pin_memory=True if torch.cuda.is_available() else False\n",
        "        )\n",
        "        \n",
        "        print(f\"\\n📊 테스트 DataLoader 설정:\")\n",
        "        print(f\"   배치 크기: {test_dataloader.batch_size}\")\n",
        "        print(f\"   전체 배치 수: {len(test_dataloader):,}개\")\n",
        "        print(f\"   전체 샘플 수: {len(test_dataset):,}개\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ 테스트 데이터 로드 실패: {e}\")\n",
        "        return None\n",
        "    \n",
        "    # 모델 확인\n",
        "    if model_loader.model is None:\n",
        "        print(\"❌ 로드된 모델이 없습니다!\")\n",
        "        return None\n",
        "    \n",
        "    # 추론 실행\n",
        "    print(f\"\\n🔮 추론 실행 중...\")\n",
        "    model_loader.model.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    ids = []\n",
        "    confidences = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_idx, batch in enumerate(test_dataloader):\n",
        "            # 데이터 GPU로 이동\n",
        "            images = batch['image'].to(device)\n",
        "            batch_ids = batch['id']\n",
        "            \n",
        "            # 모델 예측\n",
        "            outputs = model_loader.model(images)\n",
        "            probabilities = F.softmax(outputs, dim=1)\n",
        "            \n",
        "            # 예측 클래스 및 신뢰도\n",
        "            max_probs, predicted_classes = torch.max(probabilities, dim=1)\n",
        "            \n",
        "            # 결과 저장\n",
        "            predictions.extend(predicted_classes.cpu().numpy())\n",
        "            confidences.extend(max_probs.cpu().numpy())\n",
        "            ids.extend(batch_ids)\n",
        "            \n",
        "            # 진행률 출력\n",
        "            if (batch_idx + 1) % 100 == 0 or (batch_idx + 1) == len(test_dataloader):\n",
        "                progress = (batch_idx + 1) / len(test_dataloader) * 100\n",
        "                print(f\"   진행률: {progress:.1f}% ({batch_idx + 1:,}/{len(test_dataloader):,})\")\n",
        "    \n",
        "    print(f\"✅ 추론 완료!\")\n",
        "    print(f\"   총 예측 수: {len(predictions):,}개\")\n",
        "    print(f\"   평균 신뢰도: {np.mean(confidences):.3f}\")\n",
        "    \n",
        "    # 제출 파일 생성\n",
        "    print(f\"\\n📄 제출 파일 생성 중...\")\n",
        "    \n",
        "    # 예측 결과를 클래스명으로 변환\n",
        "    predicted_classes = [idx_to_class[pred] for pred in predictions]\n",
        "    \n",
        "    # 제출 파일 생성\n",
        "    submission_df = pd.DataFrame({\n",
        "        'ID': ids,\n",
        "        'rock_type': predicted_classes\n",
        "    })\n",
        "    \n",
        "    # 정렬 (ID 순서대로)\n",
        "    submission_df = submission_df.sort_values('ID').reset_index(drop=True)\n",
        "    \n",
        "    # 파일명에 타임스탬프 추가\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    model_name_short = model_loader.model_info['model_name'].split('.')[0]\n",
        "    submission_filename = f\"submission_{model_name_short}_{timestamp}.csv\"\n",
        "    submission_path = RESULTS_DIR / submission_filename\n",
        "    \n",
        "    # 파일 저장\n",
        "    submission_df.to_csv(submission_path, index=False)\n",
        "    \n",
        "    print(f\"✅ 제출 파일 생성 완료: {submission_path}\")\n",
        "    print(f\"   총 샘플 수: {len(submission_df):,}개\")\n",
        "    print(f\"   파일 크기: {os.path.getsize(submission_path) / 1024:.1f} KB\")\n",
        "    \n",
        "    # 예측 분포 확인\n",
        "    print(f\"\\n🏷️ 예측 클래스 분포:\")\n",
        "    class_counts = submission_df['rock_type'].value_counts()\n",
        "    for rock_type, count in class_counts.items():\n",
        "        percentage = count / len(submission_df) * 100\n",
        "        print(f\"   {rock_type}: {count:,}개 ({percentage:.1f}%)\")\n",
        "    \n",
        "    return {\n",
        "        'submission_df': submission_df,\n",
        "        'submission_path': submission_path,\n",
        "        'predictions': predictions,\n",
        "        'confidences': confidences,\n",
        "        'timestamp': timestamp\n",
        "    }\n",
        "\n",
        "# 추론 및 제출 파일 생성 실행\n",
        "if model_loader.model is not None:\n",
        "    inference_results = run_inference_and_create_submission()\n",
        "    if inference_results:\n",
        "        print(f\"\\n🎯 추론 작업 완료!\")\n",
        "        print(f\"   제출 파일: {inference_results['submission_path']}\")\n",
        "else:\n",
        "    print(\"❌ 모델이 로드되지 않아 추론을 실행할 수 없습니다!\")\n",
        "    inference_results = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# 📊 예측 결과 분석 및 시각화\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_and_visualize_results(inference_results):\n",
        "    \"\"\"예측 결과 상세 분석 및 시각화\"\"\"\n",
        "    \n",
        "    if inference_results is None:\n",
        "        print(\"❌ 분석할 추론 결과가 없습니다!\")\n",
        "        return\n",
        "    \n",
        "    submission_df = inference_results['submission_df']\n",
        "    confidences = np.array(inference_results['confidences'])\n",
        "    predictions = inference_results['predictions']\n",
        "    timestamp = inference_results['timestamp']\n",
        "    \n",
        "    print(\"📊 예측 결과 상세 분석\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    # 신뢰도 분석\n",
        "    print(f\"🎯 예측 신뢰도 분석:\")\n",
        "    print(f\"   평균 신뢰도: {np.mean(confidences):.3f}\")\n",
        "    print(f\"   표준편차: {np.std(confidences):.3f}\")\n",
        "    print(f\"   최고 신뢰도: {np.max(confidences):.3f}\")\n",
        "    print(f\"   최저 신뢰도: {np.min(confidences):.3f}\")\n",
        "    \n",
        "    # 신뢰도 구간별 분포\n",
        "    confidence_ranges = [\n",
        "        (0.9, 1.0, \"매우 높음\"),\n",
        "        (0.8, 0.9, \"높음\"),\n",
        "        (0.7, 0.8, \"보통\"),\n",
        "        (0.6, 0.7, \"낮음\"),\n",
        "        (0.0, 0.6, \"매우 낮음\")\n",
        "    ]\n",
        "    \n",
        "    print(f\"\\n📈 신뢰도 구간별 분포:\")\n",
        "    for min_conf, max_conf, label in confidence_ranges:\n",
        "        count = np.sum((confidences >= min_conf) & (confidences < max_conf))\n",
        "        percentage = count / len(confidences) * 100\n",
        "        print(f\"   {label} ({min_conf:.1f}-{max_conf:.1f}): {count:,}개 ({percentage:.1f}%)\")\n",
        "    \n",
        "    # 클래스별 예측 분포 시각화\n",
        "    plt.figure(figsize=(16, 12))\n",
        "    \n",
        "    # 1. 클래스별 예측 분포\n",
        "    plt.subplot(2, 3, 1)\n",
        "    class_counts = submission_df['rock_type'].value_counts()\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(class_counts)))\n",
        "    \n",
        "    bars = plt.bar(range(len(class_counts)), class_counts.values, color=colors)\n",
        "    plt.xticks(range(len(class_counts)), class_counts.index, rotation=45, ha='right')\n",
        "    plt.title('예측 클래스별 분포', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('예측 개수')\n",
        "    \n",
        "    # 막대 위에 개수 표시\n",
        "    for bar, count in zip(bars, class_counts.values):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 100,\n",
        "                f'{count:,}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 2. 신뢰도 히스토그램\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.hist(confidences, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    plt.axvline(np.mean(confidences), color='red', linestyle='--', \n",
        "                label=f'평균: {np.mean(confidences):.3f}')\n",
        "    plt.title('예측 신뢰도 분포', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('신뢰도')\n",
        "    plt.ylabel('빈도')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 3. 클래스별 평균 신뢰도\n",
        "    plt.subplot(2, 3, 3)\n",
        "    \n",
        "    # 클래스별 평균 신뢰도 계산\n",
        "    class_confidences = {}\n",
        "    for i, pred_class in enumerate(predictions):\n",
        "        class_name = idx_to_class[pred_class]\n",
        "        if class_name not in class_confidences:\n",
        "            class_confidences[class_name] = []\n",
        "        class_confidences[class_name].append(confidences[i])\n",
        "    \n",
        "    avg_confidences = {cls: np.mean(confs) for cls, confs in class_confidences.items()}\n",
        "    \n",
        "    sorted_classes = sorted(avg_confidences.items(), key=lambda x: x[1], reverse=True)\n",
        "    classes, avg_confs = zip(*sorted_classes)\n",
        "    \n",
        "    bars = plt.bar(range(len(classes)), avg_confs, color=colors[:len(classes)])\n",
        "    plt.xticks(range(len(classes)), classes, rotation=45, ha='right')\n",
        "    plt.title('클래스별 평균 신뢰도', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('평균 신뢰도')\n",
        "    plt.ylim(0, 1)\n",
        "    \n",
        "    # 막대 위에 값 표시\n",
        "    for bar, conf in zip(bars, avg_confs):\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                f'{conf:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 4. 신뢰도 vs 클래스 박스플롯\n",
        "    plt.subplot(2, 3, 4)\n",
        "    \n",
        "    # 박스플롯 데이터 준비\n",
        "    box_data = [class_confidences[cls] for cls in sorted(class_confidences.keys())]\n",
        "    box_labels = sorted(class_confidences.keys())\n",
        "    \n",
        "    plt.boxplot(box_data, labels=box_labels)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('클래스별 신뢰도 분포', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('신뢰도')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 5. 신뢰도 구간별 분포\n",
        "    plt.subplot(2, 3, 5)\n",
        "    ranges = ['매우 낮음', '낮음', '보통', '높음', '매우 높음']\n",
        "    range_counts = []\n",
        "    for min_conf, max_conf, _ in confidence_ranges:\n",
        "        count = np.sum((confidences >= min_conf) & (confidences < max_conf))\n",
        "        range_counts.append(count)\n",
        "    \n",
        "    plt.pie(range_counts, labels=ranges, autopct='%1.1f%%', colors=plt.cm.Pastel1.colors)\n",
        "    plt.title('신뢰도 구간별 분포', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    # 6. 클래스별 예측 분포 (파이 차트)\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%', colors=colors)\n",
        "    plt.title('예측 클래스 분포', fontsize=14, fontweight='bold')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    \n",
        "    # 결과 저장\n",
        "    analysis_plot_path = RESULTS_DIR / f\"prediction_analysis_{timestamp}.png\"\n",
        "    plt.savefig(analysis_plot_path, dpi=300, bbox_inches='tight')\n",
        "    print(f\"\\n📊 분석 차트 저장: {analysis_plot_path}\")\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "    return class_confidences, avg_confidences\n",
        "\n",
        "def generate_final_report(inference_results):\n",
        "    \"\"\"최종 추론 리포트 생성\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"🎯 건설용 자갈 암석 분류 AI - 추론 완료 리포트\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    # 모델 정보\n",
        "    if model_loader.model_info:\n",
        "        print(f\"\\n🤖 사용된 모델:\")\n",
        "        print(f\"   아키텍처: {model_loader.model_info['model_name']}\")\n",
        "        print(f\"   체크포인트: {os.path.basename(model_loader.model_info['model_path'])}\")\n",
        "        print(f\"   최고 성능: {model_loader.model_info['best_score']}\")\n",
        "        print(f\"   총 파라미터: {model_loader.model_info['total_params']:,}개\")\n",
        "    \n",
        "    # 추론 결과\n",
        "    if inference_results:\n",
        "        submission_df = inference_results['submission_df']\n",
        "        confidences = inference_results['confidences']\n",
        "        \n",
        "        print(f\"\\n📊 추론 결과:\")\n",
        "        print(f\"   총 예측 샘플: {len(submission_df):,}개\")\n",
        "        print(f\"   평균 신뢰도: {np.mean(confidences):.3f}\")\n",
        "        print(f\"   신뢰도 범위: {np.min(confidences):.3f} - {np.max(confidences):.3f}\")\n",
        "        \n",
        "        # 제출 파일 정보\n",
        "        print(f\"\\n📄 제출 파일:\")\n",
        "        submission_path = inference_results['submission_path']\n",
        "        print(f\"   파일명: {os.path.basename(submission_path)}\")\n",
        "        print(f\"   경로: {submission_path}\")\n",
        "        print(f\"   샘플 수: {len(submission_df):,}개\")\n",
        "        print(f\"   파일 크기: {os.path.getsize(submission_path) / 1024:.1f} KB\")\n",
        "        \n",
        "        # 예측 클래스 분포\n",
        "        print(f\"\\n🏷️ 예측 클래스 분포:\")\n",
        "        class_counts = submission_df['rock_type'].value_counts()\n",
        "        for rock_type, count in class_counts.items():\n",
        "            percentage = count / len(submission_df) * 100\n",
        "            print(f\"   {rock_type}: {count:,}개 ({percentage:.1f}%)\")\n",
        "        \n",
        "        # 생성된 파일들\n",
        "        print(f\"\\n📁 생성된 파일들:\")\n",
        "        result_files = list(RESULTS_DIR.glob(f\"*{inference_results['timestamp']}*\"))\n",
        "        for file_path in result_files:\n",
        "            print(f\"   📄 {file_path.name}\")\n",
        "        \n",
        "        print(f\"\\n✅ 추론 작업 완료!\")\n",
        "        print(f\"   다음 단계: 제출 파일을 대회 사이트에 업로드\")\n",
        "        print(f\"   경로: {submission_path}\")\n",
        "    \n",
        "    print(\"=\"*80)\n",
        "\n",
        "# 예측 결과 분석 실행\n",
        "if inference_results is not None:\n",
        "    print(\"\\n🔍 예측 결과 분석 시작...\")\n",
        "    class_confidences, avg_confidences = analyze_and_visualize_results(inference_results)\n",
        "    generate_final_report(inference_results)\n",
        "else:\n",
        "    print(\"❌ 분석할 추론 결과가 없습니다!\")\n",
        "    print(\"   위의 셀을 실행하여 추론을 완료하세요.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "yolo",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
